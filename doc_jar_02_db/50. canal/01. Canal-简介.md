<span  style="font-family: Simsun,serif; font-size: 17px; ">

### Canal 简介

Canal 是阿里巴巴开源的数据库增量订阅与消费组件，基于 MySQL/Oracle 等数据库的 Binlog/Redo 日志解析实现实时数据捕获（CDC），常用于数据库同步、缓存刷新、搜索索引入库、数据仓库/湖实时写入及跨地域多活等场景。

#### 工作原理

- 模拟 MySQL slave 协议向主库注册，获取并拉取 binlog。
- 解析 binlog 事件并转换为统一的消息格式（Insert/Update/Delete 等）。
- 通过多种 Sink（TCP、Kafka、RocketMQ、RabbitMQ、Pulsar 等）将变更数据推送到下游。

#### 优势与特性

- 实时性强：基于日志增量订阅，延迟低。
- 侵入性小：无需改动业务库表或应用代码。
- 生态丰富：多种消息/存储适配器，易于对接大数据与中间件。
- 高可用扩展：支持 HA、分片与并行消费配置。

#### 常见使用场景

- 数据库主从/异构同步（如 MySQL → ES/HBase/ClickHouse）。
- 缓存预热与失效驱动（如更新后推送至 Redis/Guava Cache）。
- 实时数仓与日志采集（作为 CDC 入湖/入仓链路的上游）。
- 搜索与推荐索引实时更新。
- 跨机房或跨云多活数据同步。

#### 基本部署步骤

1. 准备 Canal Server，配置 `instance.properties` 指向上游数据库（包含主库地址、账号、订阅起点等）。
2. 启动 Canal Server，确认与数据库的 binlog 连接正常。
3. 按需选择客户端或中间件接收端（如 Canal TCP Client、Kafka/RocketMQ Sink）。
4. 下游应用消费并按业务逻辑落地或更新索引/缓存。

#### 实践建议

- 确认数据库开启 binlog（ROW 模式便于精确变更捕获）。
- 为 Canal 账户分配只读与复制权限，避免过大权限暴露。
- 监控延迟、位点、失败重试与下游消费堆积，设置告警。
- 合理规划表过滤与字段过滤，降低无效数据传输和解析压力。
- 在多实例场景下使用分区/分库分表配置，结合客户端并行消费提升吞吐。

</span>